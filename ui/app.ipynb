{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install & imports**"
      ],
      "metadata": {
        "id": "wJJ056VUCDXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu6_x17hA_up"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio albumentations opencv-python-headless torch torchvision\n",
        "\n",
        "import os, cv2, torch, numpy as np, gradio as gr, torch.nn as nn\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install & imports**"
      ],
      "metadata": {
        "id": "BCFZgkd0CL_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# EDIT THIS if your path differs:\n",
        "MODEL_PATH = \"/content/drive/MyDrive/UMR_GAN/results/umr_pix2pix_inpaint_ssim_G.pth\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "print(\"Weights:\", MODEL_PATH, \"exists:\", os.path.exists(MODEL_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS7Y7Q9pB7vl",
        "outputId": "299bad11-78f6-447c-c93a-ed39bc228158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cpu\n",
            "Weights: /content/drive/MyDrive/UMR_GAN/results/umr_pix2pix_inpaint_ssim_G.pth exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model (UNetGenerator in_c=2 → out_c=1) and load weights**"
      ],
      "metadata": {
        "id": "tFk8bPx0CgKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, in_c=2, out_c=1):\n",
        "        super().__init__()\n",
        "        def down(i,o,bn=True):\n",
        "            L=[nn.Conv2d(i,o,4,2,1,bias=False)]\n",
        "            if bn: L.append(nn.BatchNorm2d(o))\n",
        "            L.append(nn.LeakyReLU(0.2,True))\n",
        "            return nn.Sequential(*L)\n",
        "        def up(i,o,drop=False):\n",
        "            L=[nn.ConvTranspose2d(i,o,4,2,1,bias=False), nn.BatchNorm2d(o), nn.ReLU(True)]\n",
        "            if drop: L.append(nn.Dropout(0.5))\n",
        "            return nn.Sequential(*L)\n",
        "        self.d1=down(in_c,64,False); self.d2=down(64,128)\n",
        "        self.d3=down(128,256); self.d4=down(256,512)\n",
        "        self.d5=down(512,512); self.d6=down(512,512)\n",
        "        self.d7=down(512,512); self.b=down(512,512, bn=False)  # no BN at 1×1\n",
        "        self.u1=up(512,512,True); self.u2=up(1024,512,True)\n",
        "        self.u3=up(1024,512,True); self.u4=up(1024,512)\n",
        "        self.u5=up(1024,256); self.u6=up(512,128)\n",
        "        self.u7=up(256,64)\n",
        "        self.out=nn.Sequential(nn.ConvTranspose2d(128,out_c,4,2,1), nn.Tanh())\n",
        "\n",
        "    def forward(self,x):\n",
        "        d1=self.d1(x); d2=self.d2(d1); d3=self.d3(d2); d4=self.d4(d3)\n",
        "        d5=self.d5(d4); d6=self.d6(d5); d7=self.d7(d6); b=self.b(d7)\n",
        "        u1=self.u1(b); u2=self.u2(torch.cat([u1,d7],1))\n",
        "        u3=self.u3(torch.cat([u2,d6],1)); u4=self.u4(torch.cat([u3,d5],1))\n",
        "        u5=self.u5(torch.cat([u4,d4],1)); u6=self.u6(torch.cat([u5,d3],1))\n",
        "        u7=self.u7(torch.cat([u6,d2],1))\n",
        "        return self.out(torch.cat([u7,d1],1))\n",
        "\n",
        "# Load weights (handles state_dict or wrapped dict)\n",
        "ckpt = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "state = ckpt.get(\"G\", ckpt.get(\"gen\", ckpt.get(\"generator\", ckpt.get(\"state_dict\", ckpt))))\n",
        "G = UNetGenerator(in_c=2, out_c=1).to(DEVICE)\n",
        "missing, unexpected = G.load_state_dict(state, strict=False)\n",
        "print(\"Loaded G. missing:\", missing, \"| unexpected:\", unexpected)\n",
        "G.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgiOdfwKCRs3",
        "outputId": "5241f605-590a-434d-8782-81ab2404d1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded G. missing: [] | unexpected: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNetGenerator(\n",
              "  (d1): Sequential(\n",
              "    (0): Conv2d(2, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (d2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (d3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (d4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (d5): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (d6): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (d7): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (b): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (u1): Sequential(\n",
              "    (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (u2): Sequential(\n",
              "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (u3): Sequential(\n",
              "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (u4): Sequential(\n",
              "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (u5): Sequential(\n",
              "    (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (u6): Sequential(\n",
              "    (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (u7): Sequential(\n",
              "    (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (out): Sequential(\n",
              "    (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre/Post (resize→normalize to [-1,1] and denorm to [0,1])**"
      ],
      "metadata": {
        "id": "7M9cISXxDIKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF = A.Compose([\n",
        "    A.Resize(256,256),\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,), max_pixel_value=255.0),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "def to_gray(arr_rgb):\n",
        "    return cv2.cvtColor(arr_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "def denorm01(t):\n",
        "    return (t.squeeze().cpu().numpy()*0.5 + 0.5).clip(0,1)\n"
      ],
      "metadata": {
        "id": "fEc-AKmGCflI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradio app (Denoise or Inpaint with sketch mask)**"
      ],
      "metadata": {
        "id": "fhw4ZMv8DTKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- UMR-GAN Gradio UI (denoise + inpaint) with noise match, median filter, TTA ---\n",
        "import gradio as gr, numpy as np, cv2, torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Use the same preprocessing as training/eval\n",
        "TF = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,), max_pixel_value=255.0),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "def _editor_to_mask(sketch, H=256, W=256):\n",
        "    \"\"\"Parse ImageEditor output to a binary mask (H,W) in {0,1}.\"\"\"\n",
        "    if sketch is None:\n",
        "        return np.zeros((H, W), dtype=np.uint8)\n",
        "    arr = sketch\n",
        "    if isinstance(arr, dict):                         # some gradio versions return dicts\n",
        "        for key in [\"composite\", \"image\", \"background\"]:\n",
        "            if key in arr and arr[key] is not None:\n",
        "                arr = arr[key]; break\n",
        "    arr = np.array(arr)\n",
        "    if arr.ndim == 3 and arr.shape[2] == 4:          # RGBA -> alpha\n",
        "        m = (arr[..., 3] > 0).astype(np.uint8)\n",
        "    elif arr.ndim == 3:                               # RGB -> brightness\n",
        "        m = (cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY) > 0).astype(np.uint8)\n",
        "    else:                                             # grayscale\n",
        "        m = (arr > 0).astype(np.uint8)\n",
        "    return cv2.resize(m, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "def _denorm01(t):   # [-1,1] -> [0,1] numpy\n",
        "    return (t.squeeze().cpu().numpy()*0.5 + 0.5).clip(0,1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def _run_G(x_cond):\n",
        "    return G(x_cond).cpu()\n",
        "\n",
        "def restore(img_rgb, mode, noise_sigma, use_median, use_tta, sketch):\n",
        "    # 1) to gray + resize to 256\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    gray = cv2.resize(gray, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # 2) add Gaussian noise (match training distribution); set to 0 if input already noisy\n",
        "    if noise_sigma and noise_sigma > 0:\n",
        "        noisy = np.clip(gray + np.random.normal(0, noise_sigma, gray.shape), 0, 255).astype(np.uint8)\n",
        "    else:\n",
        "        noisy = gray.copy()\n",
        "\n",
        "    # 3) mask (zero for denoise; drawn for inpaint)\n",
        "    if mode == \"Denoise (zero mask)\":\n",
        "        M = np.zeros_like(noisy, dtype=np.uint8)\n",
        "    else:\n",
        "        M = _editor_to_mask(sketch, 256, 256)  # {0,1}\n",
        "\n",
        "    # 4) preprocess to [-1,1] tensors\n",
        "    noisy_t = TF(image=noisy)[\"image\"]                  # (1,256,256)\n",
        "    mask_t  = torch.from_numpy(M).float().unsqueeze(0)  # (1,256,256)\n",
        "\n",
        "    # blank masked pixels to -1 (training convention)\n",
        "    x_img = noisy_t.clone()\n",
        "    x_img[mask_t.bool()] = -1.0\n",
        "\n",
        "    # 5) condition tensor (B=1, C=2)\n",
        "    x = torch.cat([x_img, mask_t], dim=0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    # 6) optional TTA (flip-average)\n",
        "    if use_tta:\n",
        "        xs = [x, torch.flip(x, dims=[3]), torch.flip(x, dims=[2]), torch.flip(x, dims=[2,3])]\n",
        "        outs = []\n",
        "        for k, xi in enumerate(xs):\n",
        "            yi = _run_G(xi)\n",
        "            if k == 1: yi = torch.flip(yi, dims=[3])\n",
        "            if k == 2: yi = torch.flip(yi, dims=[2])\n",
        "            if k == 3: yi = torch.flip(yi, dims=[2,3])\n",
        "            outs.append(yi)\n",
        "        out = torch.mean(torch.stack(outs, dim=0), dim=0)\n",
        "    else:\n",
        "        out = _run_G(x)\n",
        "\n",
        "    # 7) optional median filter to suppress pepper dots\n",
        "    out_np = _denorm01(out[0])\n",
        "    if use_median:\n",
        "        out_np = cv2.medianBlur((out_np*255).astype(np.uint8), 3) / 255.0\n",
        "\n",
        "    return (_denorm01(x_img), M.astype(float), out_np)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## UMR-GAN (pix2pix) — MRI Denoising & Inpainting\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            img_in = gr.Image(type=\"numpy\", label=\"Upload MRI slice (auto-resized to 256×256)\")\n",
        "            mode   = gr.Radio(choices=[\"Denoise (zero mask)\", \"Inpaint (use drawn mask)\"],\n",
        "                              value=\"Denoise (zero mask)\", label=\"Mode\")\n",
        "            noise_sigma = gr.Slider(0, 30, value=15, step=1, label=\"Add Gaussian noise σ (match training)\")\n",
        "            use_median  = gr.Checkbox(value=True,  label=\"Post-process: median 3×3 (reduce dots)\")\n",
        "            use_tta     = gr.Checkbox(value=False, label=\"TTA (flip-average)\")\n",
        "            sketch      = gr.ImageEditor(label=\"Draw Mask (paint white where missing)\")\n",
        "            btn         = gr.Button(\"Restore\")\n",
        "        with gr.Column(scale=1):\n",
        "            out1 = gr.Image(label=\"Input (masked/noisy)\", image_mode=\"L\", width=256, height=256)\n",
        "            out2 = gr.Image(label=\"Mask\",               image_mode=\"L\", width=256, height=256)\n",
        "            out3 = gr.Image(label=\"Restored\",           image_mode=\"L\", width=256, height=256)\n",
        "    btn.click(fn=restore, inputs=[img_in, mode, noise_sigma, use_median, use_tta, sketch],\n",
        "              outputs=[out1, out2, out3])\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "Ks4VpNgfDHth",
        "outputId": "1332fffc-68d1-4a8f-8838-b53783955f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://038ef6ea7de14ab509.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://038ef6ea7de14ab509.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3fE58LmDWVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORSuUzUyDV-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}